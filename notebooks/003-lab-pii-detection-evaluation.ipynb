{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII Detection Evaluation with Presidio Research\n",
    "In this notebook, we will demonstrate how to evaluate the performance of PII (Personally Identifiable Information) detection using the `presidio-research` library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we need to import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from collections import Counter\n",
    "from presidio_evaluator import InputSample, Span\n",
    "from presidio_evaluator.evaluation import Evaluator, ModelError\n",
    "from presidio_evaluator.models import PresidioAnalyzerWrapper\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counter is a Python library that allows us to count the occurrences of elements in a list. \n",
    "InputSample and Span are classes from the presidio_evaluator library that we will use to represent our data and the spans of PII in our data, respectively.\n",
    "\n",
    "## Load Data\n",
    "\n",
    "Next, we will load our data. This data should be in the form of a list of `InputSample` objects. Each `InputSample` object represents a piece of text and contains a list of `Span` objects that represent the ground truth spans of PII in the text. \n",
    "\n",
    "In this example, I create an instance of `InputSample` where `full_text` contains only one sentence: \"My name is Trang Nguyen.\". This sentence has the ground truth span declared inside the `spans` parameter. Since there are no ground truth tokenizations - which are needed for evaluation, we set `create_tags_from_span = True` to tokenize the `full_text`. The default `token_model_version` used for tokenization is `en_core_web_sm` and the IO schema. You can change these parameters to use a different model for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data as an Input Sample object\n",
    "sample = InputSample(\n",
    "    full_text = \"My name is Trang Nguyen. I live in France.\",\n",
    "    spans = [\n",
    "                Span(start_position  = 11, \n",
    "                    end_position = 22, \n",
    "                    entity_value = \"Trang Nguyen\", \n",
    "                    entity_type = \"PERSON\"),\n",
    "                Span(start_position = 33,\n",
    "                    end_position = 38,\n",
    "                    entity_value = \"Paris\",\n",
    "                    entity_type = \"LOCATION\")\n",
    "        ],\n",
    "    create_tags_from_span=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, we are iterating over the tokens and their corresponding tags in the `sample` object.\n",
    "\n",
    "The sample.tokens is a list of tokens, which are the individual words or punctuation from the full_text of the InputSample object. The sample.tags is a list of tags, where each tag represents the entity type of the corresponding token. For example, a tag of 'PERSON' indicates that the token is a person's name, while a tag of 'O' indicates that the token is not a PII entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{My: 'O'}\n",
      "{name: 'O'}\n",
      "{is: 'O'}\n",
      "{Trang: 'PERSON'}\n",
      "{Nguyen: 'PERSON'}\n",
      "{.: 'O'}\n",
      "{I: 'O'}\n",
      "{live: 'O'}\n",
      "{in: 'O'}\n",
      "{France: 'LOCATION'}\n",
      "{.: 'O'}\n",
      "Count per entity:\n",
      "[('O', 8), ('PERSON', 2), ('LOCATION', 1)]\n"
     ]
    }
   ],
   "source": [
    "for token, tag in zip(sample.tokens, sample.tags):\n",
    "    print({token: tag})\n",
    "\n",
    "entity_counter = Counter()\n",
    "for tag in sample.tags:\n",
    "    entity_counter[tag] += 1\n",
    "print(\"Count per entity:\")\n",
    "print(entity_counter.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In presidio-research package, there are several Wrapper models were created to identify and evaluate some PII model such as crf, spacy, stanza flair, presidio or Azure text analytics. In this article, I will focus on evaluating Presidio PII identification capability. \n",
    "\n",
    "First we need to declare a PresidioAnalyzerWrapper() object, which wrappers for a specific PII recognizer from presidio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities supported by this Presidio Analyzer instance:\n",
      "SG_NRIC_FIN, IN_AADHAAR, UK_NHS, IP_ADDRESS, PERSON, EMAIL_ADDRESS, URL, IN_VEHICLE_REGISTRATION, CRYPTO, US_DRIVER_LICENSE, US_ITIN, ORGANIZATION, DATE_TIME, US_BANK_NUMBER, AU_TFN, PHONE_NUMBER, LOCATION, AGE, AU_ABN, EMAIL, US_PASSPORT, NRP, AU_ACN, US_SSN, ID, IBAN_CODE, CREDIT_CARD, MEDICAL_LICENSE, AU_MEDICARE, IN_PAN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"Presidio Analyzer\"\n",
    "model = PresidioAnalyzerWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PresidioAnalyzerWrapper currently supported the following entities: SG_NRIC_FIN, IN_AADHAAR, UK_NHS, IP_ADDRESS, PERSON, EMAIL_ADDRESS, URL, IN_VEHICLE_REGISTRATION, CRYPTO, US_DRIVER_LICENSE, US_ITIN, ORGANIZATION, DATE_TIME, US_BANK_NUMBER, AU_TFN, PHONE_NUMBER, LOCATION, AGE, AU_ABN, EMAIL, US_PASSPORT, NRP, AU_ACN, US_SSN, ID, IBAN_CODE, CREDIT_CARD, MEDICAL_LICENSE, AU_MEDICARE, IN_PAN\n",
    "\n",
    "You can also perform the PII detection by using the model we just declared by using the following snippet code. As you can see, the model has predicted the entities in the text. The output is a list of tags, where each tag corresponds to a token in the text. The tags are either \"O\" (non-PII) or the entity type (e.g., \"PERSON\", \"LOCATION\") if the token is part of a PII entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII detection output by using PresidioAnalyzerWrapper model\n",
      "My name is Trang Nguyen. I live in France.\n",
      "['O', 'O', 'O', 'PERSON', 'PERSON', 'O', 'O', 'O', 'O', 'LOCATION', 'O']\n"
     ]
    }
   ],
   "source": [
    "pii_prediction = model.predict(sample)\n",
    "print(\"PII detection output by using PresidioAnalyzerWrapper model\")\n",
    "print(sample.tokens)\n",
    "print(pii_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can perform the evaluation by using the following snippet code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating <class 'presidio_evaluator.models.presidio_analyzer_wrapper.PresidioAnalyzerWrapper'>: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator(model=model)\n",
    "\n",
    "evaluation_results = evaluator.evaluate_all(dataset=[sample])\n",
    "results = evaluator.calculate_score(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "          LOCATION  O  PERSON\n",
      "LOCATION         1  0       0\n",
      "O                0  6       0\n",
      "PERSON           0  0       2\n",
      "Precision and recall\n",
      "              Entity           Precision              Recall   Number of samples\n",
      "            LOCATION             100.00%             100.00%                   1\n",
      "              PERSON             100.00%             100.00%                   2\n",
      "                 PII             100.00%             100.00%                   3\n",
      "PII F measure: 100.00%\n"
     ]
    }
   ],
   "source": [
    "entities, confmatrix = results.to_confusion_matrix()\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.DataFrame(confmatrix, columns=entities, index=entities))\n",
    "\n",
    "print(\"Precision and recall\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presidio-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
