{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PII Detection and Anonymization with Presidio\n",
    "## 1.1 Overview\n",
    "In this notebook, we will focus on the detection and de-identification of Personally Identifiable Information (PII) using Presidio, an open-source tool developed by Microsoft.\n",
    "\n",
    "PII refers to any information that can be used to identify an individual. Examples of PII include names, social security numbers, email addresses, phone numbers, and more. In the wrong hands, PII can be used for malicious purposes such as identity theft, fraud, and phishing attacks, among others. Therefore, it's crucial to ensure that PII is adequately protected, especially when dealing with large datasets.\n",
    "\n",
    "Presidio offers a robust framework for recognizing and anonymizing PII across multiple languages and data sources. It uses pre-defined recognizers to identify different types of PII, and it provides several anonymization techniques such as masking, redaction, and replacement to de-identify the data.\n",
    "\n",
    "In this hands-on lab, we will walk you through the process of using Presidio analyzer and anonymizer engines to analyze a text for PII and anonymize it. \n",
    "\n",
    "By the end of this lab, you will have a solid understanding of how to use Presidio for PII detection and de-identification, and you will be equipped with the skills to use this tool in your data privacy and security projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Simple flow of PII detection with presidio\n",
    "Presidio offers a straightforward process for PII detection, which can be broken down into the following steps:\n",
    "1. Initialize the AnalyzerEngine: The AnalyzerEngine is a core component in Presidio, it contains a set of predefined recognizers to indentify different types of PII\n",
    "2. Define a text: Specify the text that you want to analyze for PII\n",
    "3. Analyze the text: By calling analyze function. This methods returns a list of AnalyzerResult object, each representing a piece of detected PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected PII: [type: PERSON, start: 11, end: 15, score: 0.85, type: LOCATION, start: 30, end: 36, score: 0.85]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "\n",
    "\n",
    "# Define the text to analyze\n",
    "text = \"My name is John and I live in France\"\n",
    "\n",
    "# Initialize PII analyzer engine\n",
    "analyzer = AnalyzerEngine()\n",
    "\n",
    "\n",
    "# Use the analyzer to detect the PII in the text\n",
    "results = analyzer.analyze(text=text, language='en', entities=[\"LOCATION\", \"PERSON\"])\n",
    "\n",
    "# Print PII detection the results\n",
    "print(f\"Detected PII: {results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Review the result: The result returns the `entity_type` (e.g., PERSON), the starting position, and the ending position in the text. You can format this into a more readable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following PII:\n",
      "- John as PERSON\n",
      "- France as LOCATION\n"
     ]
    }
   ],
   "source": [
    "print(\"Identified the following PII:\")\n",
    "for result in results:\n",
    "    print(f\"- {text[result.start:result.end]} as {result.entity_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PII Anonymizer with Presidio\n",
    "\n",
    "After detecting PII in the text using Presidio's Analyzer engine, the next step is to anonymize this information. This is where Presidio's Anonymizer engine comes into play. The Anonymizer engine provides several methods to anonymize detected PII, including replacement, redaction, and masking.\n",
    "\n",
    "Here's a simple flow of PII anonymization with Presidio:\n",
    "\n",
    "1. **Import the necessary libraries**: In addition to the `AnalyzerEngine`, we also need to import the `AnonymizerEngine` and `AnonymizerConfig` from `presidio_anonymizer`.\n",
    "2. **Initialize the Anonymizer engine**: Similar to the Analyzer engine, we need to create an instance of the Anonymizer engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected PII: [type: PERSON, start: 11, end: 15, score: 0.85, type: LOCATION, start: 30, end: 36, score: 0.85]\n"
     ]
    }
   ],
   "source": [
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_anonymizer.entities import RecognizerResult, OperatorConfig\n",
    "\n",
    "# Initialize PII anonymizer engine\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "# Print the PII detection results from previous step\n",
    "print(f\"Detected PII: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Define the anonymization configuration**: The AnonymizerConfig class allows us to specify the anonymization method and parameters. For example, we can use the \"replace\" method to replace all detected PII with a specific string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: My name is <ANONYMIZED> and I live in <ANONYMIZED>\n",
      "items:\n",
      "[\n",
      "    {'start': 38, 'end': 50, 'entity_type': 'LOCATION', 'text': '<ANONYMIZED>', 'operator': 'replace'},\n",
      "    {'start': 11, 'end': 23, 'entity_type': 'PERSON', 'text': '<ANONYMIZED>', 'operator': 'replace'}\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use anonymizer enginze to anonymize the PII in the text\n",
    "anonymized_results = anonymizer.anonymize(text=text, \n",
    "                                          analyzer_results= results,\n",
    "                                          operators={\"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"<ANONYMIZED>\"}),\n",
    "                                                    \"LOCATION\": OperatorConfig(\"replace\", {\"new_value\": \"<ANONYMIZED>\"})})\n",
    "print(anonymized_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also encrypte the PII entities by a key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: My name is TfRw3vE9yGQGVHeBKR3gu1AaY9z9wHrn5ATCYXM8KwQ= and I live in g3hE8t4goo65WrJXTc1ZO+f17Pyzp5/u5BM1iWymWgQ=\n",
      "items:\n",
      "[\n",
      "    {'start': 70, 'end': 114, 'entity_type': 'LOCATION', 'text': 'g3hE8t4goo65WrJXTc1ZO+f17Pyzp5/u5BM1iWymWgQ=', 'operator': 'encrypt'},\n",
      "    {'start': 11, 'end': 55, 'entity_type': 'PERSON', 'text': 'TfRw3vE9yGQGVHeBKR3gu1AaY9z9wHrn5ATCYXM8KwQ=', 'operator': 'encrypt'}\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use anonymizer enginze to anonymize the PII in the text\n",
    "# Define the anonymizer_config\n",
    "anonymized_results = anonymizer.anonymize(text=text, \n",
    "                                          analyzer_results= results,\n",
    "                                          operators={\"PERSON\": OperatorConfig(\"encrypt\", {\"key\": \"WmZq4t7w!z%C&F)J\"}),\n",
    "                                                    \"LOCATION\": OperatorConfig(\"encrypt\", {\"key\": \"WmZq4t7w!z%C&F)J\"})})\n",
    "print(anonymized_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrypts back to orginal text if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: My name is Chloë\n",
      "items:\n",
      "[\n",
      "    {'start': 11, 'end': 16, 'entity_type': 'PERSON', 'text': 'Chloë', 'operator': 'decrypt'}\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from presidio_anonymizer import DeanonymizeEngine\n",
    "from presidio_anonymizer.entities import OperatorResult, OperatorConfig\n",
    "\n",
    "# Initialize the engine:\n",
    "engine = DeanonymizeEngine()\n",
    "\n",
    "# Invoke the deanonymize function with the text, anonymizer results and\n",
    "# Operators to define the deanonymization type.\n",
    "result = engine.deanonymize(\n",
    "    text=\"My name is S184CMt9Drj7QaKQ21JTrpYzghnboTF9pn/neN8JME0=\",\n",
    "    entities=[\n",
    "        OperatorResult(start=11, end=55, entity_type=\"PERSON\"),\n",
    "    ],\n",
    "    operators={\"DEFAULT\": OperatorConfig(\"decrypt\", {\"key\": \"WmZq4t7w!z%C&F)J\"})},\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Customize Presidio\n",
    "Next, we'll go over ways to customize Presidio to specific needs by adding PII recognizers, using context words, NER models and more.\n",
    "Presidio offers support for:\n",
    "- Deny-list based PII recognition: For instances such as identifying titles in text, you may want to utilize a predefined list of titles (e.g., Sir, Mr., Mrs.) that should be excluded from your data.\n",
    "- Regular-expressions based PII recognition: You might need to employ regular expressions to pinpoint customized entity patterns, like a company's user ID that begins with a specific prefix followed by a sequence of digits.\n",
    "- Rule based logic recognizer: Develop any customize recognizer with your rule based logic.\n",
    "- Leverage the additional models or services:  Presidio enables the addition of new models and languages (for example, transformers from HuggingFace) or the incorporation of external PII detection services or frameworks (such as Azure AI Language)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 Deny-list based PII recognition\n",
    "In this example, we will pass a short list of tokens which should be marked as PII if detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to define the tokens we want to treat as PII. In this example it would be a list of tittles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = [\n",
    "    \"Sir\",\n",
    "    \"Ma'am\",\n",
    "    \"Madam\",\n",
    "    \"Mr.\",\n",
    "    \"Mrs.\",\n",
    "    \"Ms.\",\n",
    "    \"Miss\",\n",
    "    \"Dr.\",\n",
    "    \"Professor\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, let's create a PatternRecognize which would scan for those title, by parsing a deny_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[type: TITLE, start: 7, end: 10, score: 1.0]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import PatternRecognizer\n",
    "titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\", deny_list=titles_list)\n",
    "\n",
    "# Call our analyzer engine with the new recognizer\n",
    "text = \"Hello, Mr. John Doe\"\n",
    "result = titles_recognizer.analyze(text, entities=[\"TITLE\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you want to detect both title and person name from this text. You need to add the title_recognizer into AnalyzerEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following PII:\n",
      "- Mr. as TITLE\n",
      "- John Doe as PERSON\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "# Add title_recognizer to the analyzer\n",
    "analyzer.registry.add_recognizer(titles_recognizer)\n",
    "# Now test the analyzer with the new recognizer\n",
    "text = \"Hello, Mr. John Doe\"\n",
    "results = analyzer.analyze(text, language=\"en\", entities=[\"TITLE\", \"PERSON\"])\n",
    "# print(results)\n",
    "print(\"Identified the following PII:\")\n",
    "for result in results:\n",
    "    print(f\"- {text[result.start:result.end]} as {result.entity_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Regular-expressions based PII recognition\n",
    "In this example, we'll showcase an simple example to add a recoginzer based on regular expression. Let's assume we want to be extremely conservative and treat any token which contains a number as PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following PII:\n",
      "- 555 as NUMBER\n",
      "- 1234 as NUMBER\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import Pattern, PatternRecognizer\n",
    "\n",
    "# Define the regex pattern in a Presidio Pattern object\n",
    "number_pattern = Pattern(name=\"numbers_pattern\", regex=\"\\d+\", score=0.5)\n",
    "\n",
    "# Define a PatternRecognizer with the number_patterns\n",
    "number_recognizer = PatternRecognizer(supported_entity=\"NUMBER\", patterns=[number_pattern])\n",
    "\n",
    "# Test the recognizer\n",
    "text = \"My phone number is 555-1234\"\n",
    "results = number_recognizer.analyze(text, entities=[\"NUMBER\"])\n",
    "print(\"Identified the following PII:\")\n",
    "for result in results:\n",
    "    print(f\"- {text[result.start:result.end]} as {result.entity_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that the new recognizer added can contain errors, both false-positive and false-negative, which would impact the entire performance of presidio. Please consider testing each recognizer on a representative dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Rule based logic recognizer\n",
    "Taking the numbers recognizer above one step further, let's say we also would like to detect numbers within words. For example \"Number One\". We can leverage the underlying spaCy token attributes, or write our own logic to detect such entities (which are not able to detect by using regular expression or deny-list)\n",
    "\n",
    "- In this example, we would create a new class, which extends from EntityRecognizer, the basic recognizer in Presidio. This abstract class requires us to implement the load method and analyze method\n",
    "- Each customize recognizer accepts an object of type NlpArtifacts, which holds pre-computed attributes on the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following PII:\n",
      "- Harry as PERSON\n",
      "- Five as NUMBER\n",
      "- Five as NUMBER\n",
      "- Five as NUMBER\n",
      "- One as NUMBER\n",
      "- Two as NUMBER\n",
      "- Three as NUMBER\n",
      "- Four as NUMBER\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from presidio_analyzer import EntityRecognizer, RecognizerResult, AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpArtifacts\n",
    "\n",
    "# New recognizer class\n",
    "class MyNumbersRecognizer(EntityRecognizer):\n",
    "    expected_confidence_level = 0.7\n",
    "    def load(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def analyze(\n",
    "            self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n",
    "    ) -> List[RecognizerResult]:\n",
    "        # Iterate over the spaCy tokens, and call token.like_num\n",
    "        for token in nlp_artifacts.tokens:\n",
    "            if token.like_num:\n",
    "                result = RecognizerResult(\n",
    "                        entity_type=\"NUMBER\",\n",
    "                        start=token.idx,\n",
    "                        end=token.idx + len(token),\n",
    "                        score=self.expected_confidence_level\n",
    "                )\n",
    "                results.append(result)\n",
    "        return results\n",
    "    \n",
    "# Now create an instance of MyNumbersRecognizer with supported_entities is NUMBER\n",
    "new_numbers_recognizer = MyNumbersRecognizer(supported_entities = [\"NUMBER\"])\n",
    "# Create an instance of the analyzer engine\n",
    "analyzer = AnalyzerEngine()\n",
    "# Add the new number recognizer to the analyzer\n",
    "analyzer.registry.add_recognizer(new_numbers_recognizer)\n",
    "\n",
    "# Test the analyzer with the new recognizer\n",
    "text = \"My name is Harry and my phone number is Five Five Five One Two Three Four\"\n",
    "results = analyzer.analyze(text, language=\"en\")\n",
    "print(\"Identified the following PII:\")\n",
    "for result in results:\n",
    "    print(f\"- {text[result.start:result.end]} as {result.entity_type}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
